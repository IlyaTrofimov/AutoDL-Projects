Start train-evaluate |skip_connect~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|nor_conv_3x3~0|skip_connect~1|nor_conv_1x1~2|
arch_config : {'channel': 16, 'num_cells': 5}

The 00/01-th seed is 111 ----------------------<.>----------------------
Does not find the existing file output/trofim-NST/specifics/LESS-|skip_connect~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|nor_conv_3x3~0|skip_connect~1|nor_conv_1x1~2|-16-5/seed-0111.pth, train and evaluate!
configs/nas-benchmark/LESS.config
Configure(scheduler='cos', eta_min=0.0, epochs=12, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=100, xshape=(1, 3, 32, 32))
Evaluate ||||||| cifar100   ||||||| Train-Num=50000, Valid-Num=10000, Train-Loader-Num=196, Valid-Loader-Num=40, batch size=256
Evaluate ||||||| cifar100   ||||||| Config=Configure(scheduler='cos', eta_min=0.0, epochs=12, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=100, xshape=(1, 3, 32, 32))
Evaluate ---->>>> ori-test   with 40 batchs
Evaluate ---->>>> x-valid    with 20 batchs
Evaluate ---->>>> x-test     with 20 batchs
[2020-10-15 13:59:02] Seed-------------------------- 111 --------------------------
FLOP = 47.1105 MB, Param = 0.350196 MB
[2020-10-15 13:59:23] Time Left: [00:03:54] epoch=000/012 :: Train [loss=-0.87784, acc@1=6.85%, acc@5=22.43%] Valid [loss=-6.21496, acc@1=11.46%, acc@5=35.14%]
[2020-10-15 13:59:44] Time Left: [00:03:30] epoch=001/012 :: Train [loss=-7.83681, acc@1=21.07%, acc@5=50.91%] Valid [loss=-8.66302, acc@1=18.46%, acc@5=48.02%]
[2020-10-15 14:00:05] Time Left: [00:03:09] epoch=002/012 :: Train [loss=-9.45849, acc@1=30.78%, acc@5=64.14%] Valid [loss=-9.63431, acc@1=24.98%, acc@5=56.90%]
[2020-10-15 14:00:27] Time Left: [00:02:50] epoch=003/012 :: Train [loss=-10.26983, acc@1=38.00%, acc@5=71.61%] Valid [loss=-10.14234, acc@1=29.10%, acc@5=62.42%]
[2020-10-15 14:00:48] Time Left: [00:02:28] epoch=004/012 :: Train [loss=-10.77223, acc@1=42.79%, acc@5=75.84%] Valid [loss=-10.74371, acc@1=33.16%, acc@5=65.12%]
[2020-10-15 14:01:09] Time Left: [00:02:07] epoch=005/012 :: Train [loss=-11.12290, acc@1=46.55%, acc@5=79.01%] Valid [loss=-11.04300, acc@1=37.24%, acc@5=68.54%]
[2020-10-15 14:01:30] Time Left: [00:01:46] epoch=006/012 :: Train [loss=-11.38545, acc@1=49.55%, acc@5=81.25%] Valid [loss=-11.73880, acc@1=43.84%, acc@5=76.38%]
[2020-10-15 14:01:51] Time Left: [00:01:24] epoch=007/012 :: Train [loss=-11.59828, acc@1=52.56%, acc@5=83.27%] Valid [loss=-12.12699, acc@1=49.16%, acc@5=81.02%]
[2020-10-15 14:02:12] Time Left: [00:01:03] epoch=008/012 :: Train [loss=-11.77587, acc@1=54.95%, acc@5=85.03%] Valid [loss=-12.31083, acc@1=51.88%, acc@5=82.44%]
[2020-10-15 14:02:33] Time Left: [00:00:42] epoch=009/012 :: Train [loss=-11.91706, acc@1=57.35%, acc@5=86.44%] Valid [loss=-12.46241, acc@1=53.64%, acc@5=83.10%]
[2020-10-15 14:02:54] Time Left: [00:00:21] epoch=010/012 :: Train [loss=-12.02442, acc@1=59.74%, acc@5=87.52%] Valid [loss=-12.57980, acc@1=55.58%, acc@5=84.58%]
[2020-10-15 14:03:15] Time Left: [00:00:00] epoch=011/012 :: Train [loss=-12.09038, acc@1=60.85%, acc@5=88.20%] Valid [loss=-12.66594, acc@1=56.70%, acc@5=85.36%]
Python  Version  : 3.7.7 (default, Mar 26 2020, 15:48:22)  [GCC 7.3.0]
Pillow  Version  : 7.0.0
PyTorch Version  : 1.4.0
cuDNN   Version  : 7603
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES=0

--------------- dataset : cifar100 ---------------
Flops = 47.1105 MB, Params = 0.350196 MB
config : OrderedDict([('scheduler', 'cos'), ('eta_min', 0.0), ('epochs', 12), ('warmup', 0), ('optim', 'SGD'), ('LR', 0.1), ('decay', 0.0005), ('momentum', 0.9), ('nesterov', True), ('criterion', 'Softmax'), ('batch_size', 256), ('class_num', 100), ('xshape', (1, 3, 32, 32))])
Training State (finish) = True

<<<***>>> The 00/01-th seed is 111 <finish> other procedures need Time Left: [00:00:00]

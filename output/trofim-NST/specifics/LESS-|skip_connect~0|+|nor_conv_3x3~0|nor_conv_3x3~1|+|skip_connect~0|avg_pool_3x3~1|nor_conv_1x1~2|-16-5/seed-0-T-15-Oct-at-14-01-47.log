Start train-evaluate |skip_connect~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|avg_pool_3x3~1|nor_conv_1x1~2|
arch_config : {'channel': 16, 'num_cells': 5}

The 00/01-th seed is 111 ----------------------<.>----------------------
Does not find the existing file output/trofim-NST/specifics/LESS-|skip_connect~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|avg_pool_3x3~1|nor_conv_1x1~2|-16-5/seed-0111.pth, train and evaluate!
configs/nas-benchmark/LESS.config
Configure(scheduler='cos', eta_min=0.0, epochs=12, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=100, xshape=(1, 3, 32, 32))
Evaluate ||||||| cifar100   ||||||| Train-Num=50000, Valid-Num=10000, Train-Loader-Num=196, Valid-Loader-Num=40, batch size=256
Evaluate ||||||| cifar100   ||||||| Config=Configure(scheduler='cos', eta_min=0.0, epochs=12, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=100, xshape=(1, 3, 32, 32))
Evaluate ---->>>> ori-test   with 40 batchs
Evaluate ---->>>> x-valid    with 20 batchs
Evaluate ---->>>> x-test     with 20 batchs
[2020-10-15 14:01:50] Seed-------------------------- 111 --------------------------
FLOP = 82.49994 MB, Param = 0.593236 MB
[2020-10-15 14:02:14] Time Left: [00:04:26] epoch=000/012 :: Train [loss=6.96851, acc@1=5.15%, acc@5=19.14%] Valid [loss=2.08214, acc@1=6.70%, acc@5=21.84%]
[2020-10-15 14:02:38] Time Left: [00:04:00] epoch=001/012 :: Train [loss=-0.68459, acc@1=10.18%, acc@5=30.22%] Valid [loss=-1.50641, acc@1=6.72%, acc@5=21.06%]
[2020-10-15 14:03:02] Time Left: [00:03:36] epoch=002/012 :: Train [loss=-3.61964, acc@1=13.66%, acc@5=36.73%] Valid [loss=-3.86778, acc@1=9.96%, acc@5=31.04%]
[2020-10-15 14:03:26] Time Left: [00:03:11] epoch=003/012 :: Train [loss=-4.76153, acc@1=16.62%, acc@5=42.69%] Valid [loss=-4.99294, acc@1=14.62%, acc@5=38.34%]
[2020-10-15 14:03:50] Time Left: [00:02:47] epoch=004/012 :: Train [loss=-5.60986, acc@1=19.24%, acc@5=46.98%] Valid [loss=-5.16545, acc@1=12.94%, acc@5=34.58%]
[2020-10-15 14:04:14] Time Left: [00:02:23] epoch=005/012 :: Train [loss=-6.18098, acc@1=21.28%, acc@5=50.25%] Valid [loss=-4.55768, acc@1=11.86%, acc@5=33.34%]
[2020-10-15 14:04:37] Time Left: [00:01:59] epoch=006/012 :: Train [loss=-6.57749, acc@1=23.09%, acc@5=52.66%] Valid [loss=-3.34145, acc@1=7.42%, acc@5=24.18%]
[2020-10-15 14:05:01] Time Left: [00:01:35] epoch=007/012 :: Train [loss=-6.90885, acc@1=24.57%, acc@5=54.64%] Valid [loss=-4.34243, acc@1=10.32%, acc@5=29.36%]
[2020-10-15 14:05:25] Time Left: [00:01:11] epoch=008/012 :: Train [loss=-7.17854, acc@1=25.78%, acc@5=56.13%] Valid [loss=-5.94721, acc@1=12.84%, acc@5=36.04%]
[2020-10-15 14:05:49] Time Left: [00:00:47] epoch=009/012 :: Train [loss=-7.43503, acc@1=26.41%, acc@5=57.49%] Valid [loss=-7.44796, acc@1=20.98%, acc@5=49.46%]
[2020-10-15 14:06:13] Time Left: [00:00:23] epoch=010/012 :: Train [loss=-7.71291, acc@1=27.42%, acc@5=58.36%] Valid [loss=-7.42338, acc@1=19.38%, acc@5=46.38%]
[2020-10-15 14:06:37] Time Left: [00:00:00] epoch=011/012 :: Train [loss=-7.90355, acc@1=27.77%, acc@5=59.04%] Valid [loss=-8.22082, acc@1=26.84%, acc@5=57.04%]
Python  Version  : 3.7.7 (default, Mar 26 2020, 15:48:22)  [GCC 7.3.0]
Pillow  Version  : 7.0.0
PyTorch Version  : 1.4.0
cuDNN   Version  : 7603
CUDA available   : True
CUDA GPU numbers : 1
CUDA_VISIBLE_DEVICES=0

--------------- dataset : cifar100 ---------------
Flops = 82.49994 MB, Params = 0.593236 MB
config : OrderedDict([('scheduler', 'cos'), ('eta_min', 0.0), ('epochs', 12), ('warmup', 0), ('optim', 'SGD'), ('LR', 0.1), ('decay', 0.0005), ('momentum', 0.9), ('nesterov', True), ('criterion', 'Softmax'), ('batch_size', 256), ('class_num', 100), ('xshape', (1, 3, 32, 32))])
Training State (finish) = True

<<<***>>> The 00/01-th seed is 111 <finish> other procedures need Time Left: [00:00:00]
